{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b7467d6",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc02d9",
   "metadata": {},
   "source": [
    "Random forest is a bagging technique that trains many decesion trees with minor modification on the split criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abce2f19",
   "metadata": {},
   "source": [
    "In case of decesion trees we train a single tree but in random forest we train many different kinds of trees on diffrent training sets obtained through bootstrap aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10774261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee08f280",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8844d6f0",
   "metadata": {},
   "source": [
    "We define a function for bagging :- Creating 1 bootstrap samples $D_{1},D_{2},D_{3}..D_{q}$ from the original dataset $D$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfaa5d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag(X,y):\n",
    "    n_samples = X.shape[0]\n",
    "    \n",
    "    indices = np.random.choice(n_samples,size=n_samples,replace=True)\n",
    "    \n",
    "    return X[indices],y[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8359205d",
   "metadata": {},
   "source": [
    "# Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dd25173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting(y):\n",
    "    counter = Counter(y)\n",
    "    most_common = counter.most_common(1)[0][0]\n",
    "    return most_common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472e4a7c",
   "metadata": {},
   "source": [
    "We create $\\texttt{RandomForest}$ class with the following parameters:\n",
    "- number of tree = 10\n",
    "- minimum number of samples = 2\n",
    "- maximum depth = 100\n",
    "\n",
    "The $\\texttt{max_features}$ is a parameter which can be set by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "618fe744",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifier():\n",
    "    def __init__(self,n_trees=10,min_sample_split=2,max_depth=100,max_features=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.min_sample_split = min_sample_split\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.trees = []\n",
    "        \n",
    "        for _ in range(self.n_trees):\n",
    "            tree = DecisionTreeClassifier(\n",
    "                max_depth=self.max_depth,\n",
    "                max_features= self.max_features \n",
    "            )\n",
    "            X_sample,y_sample = bag(X,y)\n",
    "            \n",
    "            tree.fit(X_sample,y_sample)\n",
    "            self.trees.append(tree)\n",
    "            \n",
    "        \n",
    "    def predict(self,X):\n",
    "        tree_predict = np.array([tree.predict(X) for tree in self.trees])\n",
    "        tree_predict = np.swapaxes(tree_predict,0,1)\n",
    "        y_pred = [majority_voting(tree_pred) for tree_pred in tree_predict]\n",
    "        \n",
    "        return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbccd74",
   "metadata": {},
   "source": [
    "# Implementation of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "361de136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def accuracy(y_true,y_pred):\n",
    "    accuracy = np.sum(y_true==y_pred)/len(y_true)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "data = datasets.load_breast_cancer()\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier(n_trees=10,max_depth=10,max_features='sqrt')\n",
    "\n",
    "trees = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "635131f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4be425c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {accuracy(y_test,y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f92463",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "42f312fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7f700969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradBoost(model,X_train,y_train,X_test,y_test,boosting_rounds,learning_rate:float  =0.1):\n",
    "    y_hat_train = np.repeat(np.mean(y_train),len(y_train))\n",
    "    \n",
    "    y_hat_test = np.repeat(np.mean(y_train),len(X_test))\n",
    "    \n",
    "    resudials = y_train - y_hat_train\n",
    "    \n",
    "    for i in range(boosting_rounds):\n",
    "        \n",
    "        model = model.fit(X_train,resudials)\n",
    "        y_hat_train = y_hat_train + model.predict(X_train)*learning_rate\n",
    "        \n",
    "        y_hat_test = y_hat_test + model.predict(X_test)*learning_rate\n",
    "        \n",
    "        \n",
    "        resudials = y_train - y_hat_train\n",
    "    return y_hat_train,y_hat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "147908b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X,y = make_regression(n_samples=1000,n_features=20,n_informative=15,n_targets=1,bias=0,noise=20,shuffle=True,random_state=13)\n",
    "\n",
    "X_train = X[:800,:]\n",
    "y_train = y[:800]\n",
    "\n",
    "X_test = X[800:,:]\n",
    "y_test = y[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e91751db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor(criterion='squared_error',max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b4522e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_round:5\n",
      "n_round:10\n",
      "n_round:15\n",
      "n_round:20\n",
      "n_round:25\n",
      "n_round:30\n",
      "n_round:35\n",
      "n_round:40\n",
      "n_round:45\n",
      "n_round:50\n",
      "n_round:55\n",
      "n_round:60\n",
      "n_round:65\n",
      "n_round:70\n",
      "n_round:75\n",
      "n_round:80\n",
      "n_round:85\n",
      "n_round:90\n",
      "n_round:95\n",
      "n_round:100\n"
     ]
    }
   ],
   "source": [
    "mse_train =[]\n",
    "n_rounds = np.arange(5,101,5)\n",
    "for n_round in n_rounds:\n",
    "    y_hat_train,y_hat_test = GradBoost(model,X_train,y_train,X_test,y_test,boosting_rounds=n_round)\n",
    "    print(f'n_round:{n_round}')\n",
    "    mse_train.append(np.mean(y_train - y_hat_train)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f589f9ea",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
